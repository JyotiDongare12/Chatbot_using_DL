{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAX-8TaSzrto"
   },
   "source": [
    "# Final function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 25524,
     "status": "ok",
     "timestamp": 1601402637595,
     "user": {
      "displayName": "Subrata Maji",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghxu8VIGqB6XL51-t5wM_f1R1LdmEePYHIwb9b-=s64",
      "userId": "03124174213573157612"
     },
     "user_tz": -330
    },
    "id": "yGYcySlezo2b",
    "outputId": "8847fa60-9717-4efc-c194-85e5888a968d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV-RNDz9zwqw"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXOuAcM30DP4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, string, nltk, spacy, pickle\n",
    "import random as rn\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Softmax\n",
    "from tensorflow.keras.layers import Bidirectional, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "executionInfo": {
     "elapsed": 7627,
     "status": "ok",
     "timestamp": 1601402660586,
     "user": {
      "displayName": "Subrata Maji",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghxu8VIGqB6XL51-t5wM_f1R1LdmEePYHIwb9b-=s64",
      "userId": "03124174213573157612"
     },
     "user_tz": -330
    },
    "id": "aaAak6NM1PYd",
    "outputId": "cdb32b53-7c34-4bf5-a804-882d6b1fb576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting symspellpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/af/e71fcca6a42b6a63f518b0c1627e1f67822815cb0cf71e6af05acbd75c78/symspellpy-6.7.0-py3-none-any.whl (2.6MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6MB 4.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.18.5)\n",
      "Installing collected packages: symspellpy\n",
      "Successfully installed symspellpy-6.7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spelling Corrections\n",
    "\n",
    "# Install package\n",
    "!pip install symspellpy\n",
    "\n",
    "# Using symspell to correct spelling\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "bigram_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
    "\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7W5LUz-cuGDb"
   },
   "outputs": [],
   "source": [
    "# Loading functions from modules\n",
    "from TextCleaning import clean_text  # Cleaning\n",
    "from Preprocessing import preprocess  # Preprocess\n",
    "from Interference import beam_predict, predict  # Prediction\n",
    "from GetModel import get_model  # To get the compiled model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJGCir12zuQc"
   },
   "source": [
    "## Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SpvTMCWp7MKO"
   },
   "outputs": [],
   "source": [
    "#-------------------------------------\n",
    "# Parameters\n",
    "#-------------------------------------\n",
    "\n",
    "# fixing numpy RS\n",
    "np.random.seed(42)\n",
    "# fixing tensorflow RS\n",
    "tf.random.set_seed(32)\n",
    "# python RS\n",
    "rn.seed(12)\n",
    "\n",
    "# Taking maximum words 38\n",
    "MAXLEN = 39\n",
    "QSN_VOCAB_SIZE = 46789\n",
    "ANS_VOCAB_SIZE = 25445\n",
    "EMBEDDING_SIZE = 300\n",
    "LSTM_UNITS = 128\n",
    "BATCH_SIZE = 480\n",
    "SCORE_FUN = \"concat\"\n",
    "\n",
    "# Path to load all necessary files\n",
    "FILEPATH = './preprocessed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cplEGUG7U32"
   },
   "outputs": [],
   "source": [
    "# Raw data file\n",
    "raw_data = pickle.load(open('data_conv.pkl', 'rb'))\n",
    "\n",
    "# Loading data\n",
    "#train, validation = pickle.load(open(FILEPATH+'spelldata_train_val.pkl', 'rb'))\n",
    "\n",
    "# Load tokenizers\n",
    "enc_tokenizer, dec_tokenizer = pickle.load(open(FILEPATH+'spelltokenizer_obj.pkl', 'rb'))\n",
    "\n",
    "# Load embedding matrix\n",
    "qsn_embedding_matrix, ans_embedding_matrix = pickle.load(open(FILEPATH+'spellembedding_matrix.pkl', 'rb'))\n",
    "\n",
    "# Model's weight\n",
    "MODEL_WEIGHT_PATH = FILEPATH + 'checkpoint'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elRqu0lq4H8u"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJ0NliTvl7a_"
   },
   "outputs": [],
   "source": [
    "# Loading the compiled seq2seq model from module\n",
    "model = get_model(QSN_VOCAB_SIZE, ANS_VOCAB_SIZE, EMBEDDING_SIZE, LSTM_UNITS, MAXLEN, BATCH_SIZE, \\\n",
    "                           SCORE_FUN, qsn_embedding_matrix, ans_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 5421,
     "status": "ok",
     "timestamp": 1601402708043,
     "user": {
      "displayName": "Subrata Maji",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghxu8VIGqB6XL51-t5wM_f1R1LdmEePYHIwb9b-=s64",
      "userId": "03124174213573157612"
     },
     "user_tz": -330
    },
    "id": "WZKN-SgP6S8q",
    "outputId": "5eed9da1-fa5b-4279-95fb-3ee833875844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f914c544438>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best model's weights from disk\n",
    "model.load_weights(MODEL_WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXxpmplN-zqb"
   },
   "source": [
    "## Final func 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cb9vlfw0N6Em"
   },
   "outputs": [],
   "source": [
    "def final_fun_1(X, model, enc_tokenizer, dec_tokenizer, seq_len , sym_spell):\n",
    "    \"\"\"\n",
    "    This function includes entire pipeline, from data preprocessing to making final predictions.\n",
    "    It takes in raw data as input. It returns predictions for given inputs.\n",
    "    Here the input can be a single point or a set of points.\n",
    "    \n",
    "    Arguments:\n",
    "        X: Raw data, list of strings\n",
    "        model: Best model\n",
    "        enc_tokenizer: Quesion Tokenizer object\n",
    "        dec_tokenizer: Answer Tokenizer object\n",
    "        seq_len: Maximum length of any sequence\n",
    "        sym_spell: Symspell object after loading with proper vocab\n",
    "    \"\"\"\n",
    "    # If input is string, making it as list of strings\n",
    "    if isinstance(X, str):\n",
    "        X = [X]\n",
    "\n",
    "    # Cleaning raw data\n",
    "    input_sentences = clean_text(X)\n",
    "    # Preprocessing, spell correction\n",
    "    input_sentences = preprocess(input_sentences, sym_spell, seq_len)\n",
    "    \n",
    "    pred_answers = []  # List to store model predictions\n",
    "    for sent in input_sentences:\n",
    "        # Using beam search from module Interference\n",
    "        # Inside the function performing tokenization and padding\n",
    "        pred = beam_predict(sent, model, enc_tokenizer, dec_tokenizer, seq_len)\n",
    "        \n",
    "        pred_answers.append(pred)\n",
    "\n",
    "    return pred_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjXTkiNFA0cM"
   },
   "outputs": [],
   "source": [
    "# Taking 10 random raw datapoints\n",
    "sample = raw_data.sample(10)[['question', 'answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 1057,
     "status": "ok",
     "timestamp": 1601402779710,
     "user": {
      "displayName": "Subrata Maji",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghxu8VIGqB6XL51-t5wM_f1R1LdmEePYHIwb9b-=s64",
      "userId": "03124174213573157612"
     },
     "user_tz": -330
    },
    "id": "KlDTR6ZCQMGu",
    "outputId": "fb976e9b-80f8-438f-8805-b56c0fbe86f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>628361</th>\n",
       "      <td>@ChaseSupport Face ID works and then after a f...</td>\n",
       "      <td>@638968 Thank you for reaching out to us. We w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582187</th>\n",
       "      <td>@Ask_Spectrum why is kyle Texas internet down ...</td>\n",
       "      <td>@603070 Thank you for reaching out. I am sorry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450276</th>\n",
       "      <td>@Delta I like to call out good customer servic...</td>\n",
       "      <td>@498254 Hey, so happy to know we're exceeding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697111</th>\n",
       "      <td>Pitiful chicken and avocado sarnie from @sains...</td>\n",
       "      <td>@248554 Sorry Joy, can you tell me the barcode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476400</th>\n",
       "      <td>Estoy muy molesto con @116875... me mandaron m...</td>\n",
       "      <td>@193933 Por favor, envíanos la información uti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727293</th>\n",
       "      <td>Shout out to @SouthwestAir for giving me my fl...</td>\n",
       "      <td>@289561 We hope the surgery goes well, Jade! H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529275</th>\n",
       "      <td>@115879 do you guys have Lyft passes??? I lite...</td>\n",
       "      <td>@222938 If you did not receive it this time ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461094</th>\n",
       "      <td>@O2 could you tell me expected delivery times ...</td>\n",
       "      <td>@123248 Hi, the expected delivery time was mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260938</th>\n",
       "      <td>@hulu_support When casting the World Series to...</td>\n",
       "      <td>@347763 Yikes! Are you streaming from iOS or A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550114</th>\n",
       "      <td>My iPhone before iOS11: Running smoothly &amp;amp;...</td>\n",
       "      <td>@577753 Let's work together to resolve the beh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question                                             answer\n",
       "628361  @ChaseSupport Face ID works and then after a f...  @638968 Thank you for reaching out to us. We w...\n",
       "582187  @Ask_Spectrum why is kyle Texas internet down ...  @603070 Thank you for reaching out. I am sorry...\n",
       "450276  @Delta I like to call out good customer servic...  @498254 Hey, so happy to know we're exceeding ...\n",
       "697111  Pitiful chicken and avocado sarnie from @sains...  @248554 Sorry Joy, can you tell me the barcode...\n",
       "476400  Estoy muy molesto con @116875... me mandaron m...  @193933 Por favor, envíanos la información uti...\n",
       "727293  Shout out to @SouthwestAir for giving me my fl...  @289561 We hope the surgery goes well, Jade! H...\n",
       "529275  @115879 do you guys have Lyft passes??? I lite...  @222938 If you did not receive it this time ar...\n",
       "461094  @O2 could you tell me expected delivery times ...  @123248 Hi, the expected delivery time was mor...\n",
       "260938  @hulu_support When casting the World Series to...  @347763 Yikes! Are you streaming from iOS or A...\n",
       "550114  My iPhone before iOS11: Running smoothly &amp;...  @577753 Let's work together to resolve the beh..."
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1748,
     "status": "ok",
     "timestamp": 1601402821243,
     "user": {
      "displayName": "Subrata Maji",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghxu8VIGqB6XL51-t5wM_f1R1LdmEePYHIwb9b-=s64",
      "userId": "03124174213573157612"
     },
     "user_tz": -330
    },
    "id": "PXn1AjHzQbvp",
    "outputId": "0cb06bf3-1306-4dfa-a4fc-d0f811147221"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i apologize for the inconvenience i will be glad to assist you can you do me your name and acct or phone job']"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input is a single data point\n",
    "final_fun_1(sample['question'].values[1], model, enc_tokenizer, dec_tokenizer, MAXLEN, sym_spell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "executionInfo": {
     "elapsed": 8003,
     "status": "ok",
     "timestamp": 1601402836861,
     "user": {
      "displayName": "Subrata Maji",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghxu8VIGqB6XL51-t5wM_f1R1LdmEePYHIwb9b-=s64",
      "userId": "03124174213573157612"
     },
     "user_tz": -330
    },
    "id": "6x9oHO_JRSX8",
    "outputId": "ce5f70d2-031f-4312-e20e-e027597a56b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we would like to help you with your iphone please do us and we will get started',\n",
       " 'i apologize for the inconvenience i will be glad to assist you can you do me your name and acct or phone job',\n",
       " 'we are so glad to hear that you had a great flight with us we are glad to hear that you had a great flight',\n",
       " 'i there sorry about this could you send me a pic of the bar code please which store did you buy these from robbie',\n",
       " 'hold lament mos al inconvenience for favor sig enos in twitter para is instructions in message director',\n",
       " 'hey there we would like to look into this please do us the phone number on your account',\n",
       " 'i am sorry for the delay we are working hard to get your order working as quickly as possible as possible please do not provide your order details as we consider them to be personal information our page',\n",
       " 'sorry for the trouble we are actively working to resolve these issues now we appreciate your patience',\n",
       " 'we would like to help with your battery issue please do us to continue working with your iphone and we will continue there']"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input is set of data points\n",
    "final_fun_1(sample['question'].values, model, enc_tokenizer, dec_tokenizer, MAXLEN, sym_spell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "executionInfo": {
     "elapsed": 55232,
     "status": "ok",
     "timestamp": 1601404851596,
     "user": {
      "displayName": "Subrata Maji",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghxu8VIGqB6XL51-t5wM_f1R1LdmEePYHIwb9b-=s64",
      "userId": "03124174213573157612"
     },
     "user_tz": -330
    },
    "id": "i2ErmAbwUFkh",
    "outputId": "e32e0c5d-e4af-485b-c4b7-ba7956af0d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello sir need help\n",
      "Bot : we are here to help please do us your email address and more details so we can follow up\n",
      "User: I want to cancel my booking\n",
      "Bot : i there we are sorry you are having problems booking please do us your booking reference full name and email address we will take a look\n",
      "User: that's good. Thank you :)\n",
      "Bot : we are so glad you enjoyed your flight with us today\n",
      "User: q\n"
     ]
    }
   ],
   "source": [
    "# Use it as interactive chatting\n",
    "\n",
    "user_inp = input(\"User: \")\n",
    "while user_inp.lower() != 'q':\n",
    "    print(\"Bot :\", final_fun_1(user_inp, model, enc_tokenizer, dec_tokenizer, MAXLEN, sym_spell)[0])\n",
    "    user_inp = input(\"User: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2pPgm4x_ad7"
   },
   "source": [
    "## Final func 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3BQRoyFXR4w"
   },
   "outputs": [],
   "source": [
    "def final_fun_2(X, Y, model, enc_tokenizer, dec_tokenizer, seq_len, sym_spell, batch_size=128):\n",
    "    \"\"\"\n",
    "    This function includes entire pipeline, from data preprocessing to making final predictions.\n",
    "    It takes in raw data as input along with its target values.\n",
    "    Returns the metric value that is BLEU score on X and Y\n",
    "\n",
    "    Arguments:\n",
    "        X: Raw input data\n",
    "        Y: Raw target data\n",
    "        enc_tokenizer: Question tokenizer\n",
    "        dec_tokenizer: Answer tokenizer\n",
    "        seq_len: Max length of input and output\n",
    "        sym_spell: symspell object loaded with vocab\n",
    "        batch_size: batch size value, to be used while predicting in batches\n",
    "    \"\"\"\n",
    "    # Cleaning raw input and target data\n",
    "    input_sentences = clean_text(X)\n",
    "    target_sentences = clean_text(Y)\n",
    "    \n",
    "    # Spelling correction and preprocessing\n",
    "    input_sentences, target_sentences = preprocess(input_sentences, sym_spell, seq_len, target_sentences)\n",
    "\n",
    "    # Predicting in batches\n",
    "    start = 0\n",
    "    pred_results = []  # Predicted result by model\n",
    "    while start < len(input_sentences):\n",
    "        batch_result = predict(input_sentences[start:start+batch_size], model, enc_tokenizer, dec_tokenizer, seq_len)\n",
    "        pred_results.extend(batch_result)\n",
    "\n",
    "        start += batch_size\n",
    "\n",
    "    # Metric value, here using BLEU score\n",
    "    model_bleu = []\n",
    "    for pred, true in zip(pred_results, target_sentences):\n",
    "        original = [true.split(),]  # target sentence\n",
    "        translated = pred.split()  # Model predicted sentence\n",
    "        # Getting BLEU score for a sent\n",
    "        bleu_score = bleu.sentence_bleu(original, translated)\n",
    "        model_bleu.append(bleu_score)\n",
    "    \n",
    "    # Average BLEU score of given data\n",
    "    metric_value = (sum(model_bleu) / len(model_bleu))\n",
    "\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNPLTCsMa44O"
   },
   "outputs": [],
   "source": [
    "# Taking 10,000 random samples\n",
    "sample = raw_data.sample(10000)[['question', 'answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1601404742781,
     "user": {
      "displayName": "Subrata Maji",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghxu8VIGqB6XL51-t5wM_f1R1LdmEePYHIwb9b-=s64",
      "userId": "03124174213573157612"
     },
     "user_tz": -330
    },
    "id": "xxlKURZEYvyq",
    "outputId": "dedb8eee-5ee0-443c-c986-f430eaf2c500"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3983806167597698"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metric value for the given data\n",
    "final_fun_2(sample['question'].values, sample['answer'].values, model, enc_tokenizer, dec_tokenizer, MAXLEN, sym_spell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueHLKp2TIfNX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMHGjJwy+1ccso4bSENRQc6",
   "collapsed_sections": [],
   "name": "Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
